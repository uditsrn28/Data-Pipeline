bolts:
- className: data.pipeline.bolts.Normalization
  id: normalization
  parallelism: 1
- className: data.pipeline.bolts.Splitter
  id: splitter
  parallelism: 1
components:
- className: org.apache.storm.kafka.ZkHosts
  constructorArgs:
  - [ZOOKEEPER_IPS]
  - /brokers
  id: zkHosts
- className: org.apache.storm.spout.RawMultiScheme
  id: stringMultiScheme
- className: org.apache.storm.kafka.SpoutConfig
  constructorArgs:
  - ref: zkHosts
  - raw_data_test
  - /raw_data_test
  - datapipeline_consumer
  id: datapipeline_spoutconfig
  properties:
  - name: startOffsetTime
    value: -1
  - name: useStartOffsetTimeIfOffsetOutOfRange
    value: true
  - name: scheme
    ref: stringMultiScheme
  - name: retryLimit
    value: 1
config:
  topology.workers: 1
  topology.max.spout.pending: 950
  topology.message.timeout.secs: 210
  topology.acker.executors: 2
  topology.executor.send.buffer.size: 16384
  topology.executor.receive.buffer.size: 16384
  topology.transfer.buffer.size: 32
  topology.reciever.buffer.size: 16
  topology.worker.childopts: "-Xmx6096m -Xms4096m -XX:+UseG1GC -XX:NewSize=256m -XX:CMSInitiatingOccupancyFraction=70 -XX:-CMSConcurrentMTEnabled -Djava.net.preferIPv4Stack=true"
  nimbus.thrift.max_buffer_size: 20480000
name: 'data_pipeline'
spouts:
- className: org.apache.storm.kafka.KafkaSpout
  constructorArgs:
  - ref: datapipeline_spoutconfig
  id: datapipeline_spout
  parallelism: 1
streams:
- from: datapipeline_spout 
  grouping:
    streamId: default
    type: SHUFFLE
  name: kafka_to_splitter
  to: splitter
- from: splitter
  grouping:
    streamId: default
    type: FIELDS
    args: ["user_name"]
  name: splitter_to_normalization
  to: normalization
